{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit43b0aca25f3a478a89236e706d769e39",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construim LeNet in Keras\n",
    "### Primada incarcam so preparam baza de date MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#incarcare baza de date MNIST \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Stocarea a numerlor in randuri si coloane\n",
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[1].shape[0]\n",
    "\n",
    "#transformam baza de date in forma/shape nesecara lui keras\n",
    "#trebuie sa adugam 4 dimensiunl baza de date prin schibarea \n",
    "#formei/shape imagini originale de la (60000,28,28) la (60000,28,28,1)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "#Stocheaza forma/shape unie singure imagini\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#Schimba tipul imagini catre float32 \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#Normalizarea bazei de date prin schimbarea range de la (0-255) la (0-1)\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "\n",
    "# Hot encode \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acum sa cream straturile pentru a reproduce LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\Harum\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nModel: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 28, 28, 20)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 14, 14, 50)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 2450)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               1225500   \n_________________________________________________________________\nactivation_3 (Activation)    (None, 500)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                5010      \n_________________________________________________________________\nactivation_4 (Activation)    (None, 10)                0         \n=================================================================\nTotal params: 1,256,080\nTrainable params: 1,256,080\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "# creare model\n",
    "model = Sequential()\n",
    "\n",
    "#Steaza 2 CRP( Convolution, ReLU, Pooling)\n",
    "model.add(Conv2D(20, (5,5), padding= \"same\", input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(50,(5,5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "#Full connected layers (w/ ReLU)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Softmax (petru clasificare)\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#complile model\n",
    "model.compile(optimizer= keras.optimizers.Adadelta(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acum sa instruim LeNet in baza de date MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\Harum\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 9s 153us/step - loss: 0.1862 - accuracy: 0.9418 - val_loss: 0.0482 - val_accuracy: 0.9843\nEpoch 2/10\n60000/60000 [==============================] - 7s 122us/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.0359 - val_accuracy: 0.9885\nEpoch 3/10\n60000/60000 [==============================] - 7s 123us/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0246 - val_accuracy: 0.9927\nEpoch 4/10\n60000/60000 [==============================] - 7s 122us/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0247 - val_accuracy: 0.9917\nEpoch 5/10\n60000/60000 [==============================] - 7s 121us/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0331 - val_accuracy: 0.9886\nEpoch 6/10\n60000/60000 [==============================] - 7s 121us/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0231 - val_accuracy: 0.9929\nEpoch 7/10\n60000/60000 [==============================] - 7s 120us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0309 - val_accuracy: 0.9912\nEpoch 8/10\n60000/60000 [==============================] - 7s 121us/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0240 - val_accuracy: 0.9929\nEpoch 9/10\n60000/60000 [==============================] - 7s 119us/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0302 - val_accuracy: 0.9924\nEpoch 10/10\n60000/60000 [==============================] - 7s 119us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0286 - val_accuracy: 0.9924\n10000/10000 [==============================] - 1s 96us/step\nTest loss:  0.028551693137499206\nTest accuracy:  0.9923999905586243\n"
    }
   ],
   "source": [
    "#Parametri de instruire\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test,y_test),\n",
    "                    shuffle=True\n",
    ")\n",
    "\n",
    "model.save('c:/Users/Harum/Documents/13/mnist_LeNet.h5')\n",
    "\n",
    "#Evaluarea performantei modelui instruit\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R"
   ]
  }
 ]
}